{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habibur8rahaman/CSE431/blob/main/submission%203/Sentiment_Analysis_with_CNN_and_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwZa81ThPbt3"
      },
      "source": [
        "## Setting the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj1dnOyZOUv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91bcd274-2a2c-4207-d05e-e1c4ad6f3ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0M1fdcBOf_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57865d1c-7aa0-49d1-fe76-c05ea047ee17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/CNN\n",
            " a1_IMDB_Dataset.csv\t\t c1_lstm_model_acc_0.836.h5\t 'CNN Results.csv'\n",
            " a2_glove.6B.100d.txt\t\t c1_lstm_model_acc_0.85.h5\t 'hotel reviews.csv'\n",
            "'attraction spots reviews.csv'\t c2_IMDb_Unseen_Predictions.csv  'RNN Results.csv'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/CNN\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-vpR9QCOn2i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "q6FO9rxjxHe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNL6yy_DO0n1"
      },
      "outputs": [],
      "source": [
        "movie_reviews = pd.read_csv(\"hotel reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elu2E2KjPBJX"
      },
      "outputs": [],
      "source": [
        "movie_reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua8sjtdaPIAq"
      },
      "outputs": [],
      "source": [
        "movie_reviews.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRIDYlo4O8Va"
      },
      "outputs": [],
      "source": [
        "movie_reviews.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys4A3cAFPSYI"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x='sentiment', data=movie_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAVIsg26PVZC"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ6a6aKjPORv"
      },
      "outputs": [],
      "source": [
        "movie_reviews[\"review\"][17]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPFVY9UtPnkY"
      },
      "outputs": [],
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    '''Removes HTML tags: replaces anything between opening and closing <> with empty space'''\n",
        "\n",
        "    return TAG_RE.sub('', text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "D3GyEDf7DwFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBuD9E20PZDb"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    '''Cleans text data up, leaving only 2 or more char long non-stepwords composed of A-Z & a-z only\n",
        "    in lowercase'''\n",
        "\n",
        "    sentence = sen.lower()\n",
        "\n",
        "    sentence = remove_tags(sentence)\n",
        "\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "    sentence = pattern.sub('', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPSBPltpQDPp"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZXW5YCbQGoW"
      },
      "outputs": [],
      "source": [
        "X[17]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EKC4DJTQKsB"
      },
      "outputs": [],
      "source": [
        "y = movie_reviews['sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZPyxSQVQPT_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsF3k9QbQc5q"
      },
      "source": [
        "## Preparing embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "kZ5kWzGKeAgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "vocab_length"
      ],
      "metadata": {
        "id": "vn-Rj21reKVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "9-QqBAR0hz22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH4uFszlRGPk"
      },
      "outputs": [],
      "source": [
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('a2_glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN6SP61FSDZB"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "id": "fjwFEeCmiAPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training with:"
      ],
      "metadata": {
        "id": "OW-AbfS3jNy_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMulFBC4SfAY"
      },
      "source": [
        "## Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzNlGNGGUhVx"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbVF6c4ASgUs"
      },
      "outputs": [],
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "cnn_model.add(embedding_layer)\n",
        "\n",
        "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XayF5sTqSlP_"
      },
      "outputs": [],
      "source": [
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaF5Rc6GSnDY"
      },
      "outputs": [],
      "source": [
        "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTqK3hr6VNUi"
      },
      "outputs": [],
      "source": [
        "score = cnn_model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQhafHPmSvpG"
      },
      "outputs": [],
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLdZa9GNSyAy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnn_model_history.history['acc'])\n",
        "plt.plot(cnn_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_model_history.history['loss'])\n",
        "plt.plot(cnn_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QTts_XPS1Wn"
      },
      "source": [
        "## Recurrent Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iLtWqoMVwU5"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ccqZ-8kS2el"
      },
      "outputs": [],
      "source": [
        "lstm_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "\n",
        "lstm_model.add(embedding_layer)\n",
        "lstm_model.add(LSTM(128))\n",
        "\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk00Ss9HS68g"
      },
      "outputs": [],
      "source": [
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(lstm_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMhhaZUaS9jF"
      },
      "outputs": [],
      "source": [
        "lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = lstm_model.evaluate(X_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "w7il9EjzlAaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j71n54zS9mc"
      },
      "outputs": [],
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiibO1EuS9qB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lstm_model_history.history['acc'])\n",
        "plt.plot(lstm_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(lstm_model_history.history['loss'])\n",
        "plt.plot(lstm_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save(f\"./c1_lstm_model_acc_{round(score[1], 3)}.h5\", save_format='h5')"
      ],
      "metadata": {
        "id": "YwXAHNsnnSdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF77MN1uTHbG"
      },
      "source": [
        "# Making Predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "0i2Qws60ogQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_reviews = pd.read_csv(\"attraction spots reviews.csv\")"
      ],
      "metadata": {
        "id": "qZiniS4-guUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_reviews = sample_reviews['Review Text']\n",
        "\n",
        "unseen_processed = []\n",
        "for review in unseen_reviews:\n",
        "  review = preprocess_text(review)\n",
        "  unseen_processed.append(review)"
      ],
      "metadata": {
        "id": "aiXGG5k9VLVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_tokenized = word_tokenizer.texts_to_sequences(unseen_processed)\n",
        "\n",
        "unseen_padded = pad_sequences(unseen_tokenized, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "A8Ln84UfVZhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_sentiments = cnn_model.predict(unseen_padded)"
      ],
      "metadata": {
        "id": "PRdXVnMmZ8-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_sentiments = lstm_model.predict(unseen_padded)"
      ],
      "metadata": {
        "id": "4bh5LsCZhy7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_reviews['Raw Predicted Sentiments'] = unseen_sentiments\n",
        "sample_reviews['Predicted Sentiments'] = np.round(unseen_sentiments*10,1)\n",
        "\n",
        "df_raw_prediction_sentiments = pd.DataFrame(sample_reviews['Raw Predicted Sentiments'], columns = ['Raw Predicted Sentiments'])\n",
        "df_prediction_sentiments = pd.DataFrame(sample_reviews['Predicted Sentiments'], columns = ['Predicted Sentiments'])\n",
        "df_movie                 = pd.DataFrame(sample_reviews['Spot'], columns = ['Spot'])\n",
        "df_review_text           = pd.DataFrame(sample_reviews['Review Text'], columns = ['Review Text'])\n",
        "df_imdb_rating           = pd.DataFrame(sample_reviews['Rating'], columns = ['Rating'])\n",
        "\n",
        "\n",
        "dfx=pd.concat([df_movie, df_review_text, df_imdb_rating, df_raw_prediction_sentiments, df_prediction_sentiments], axis=1)\n",
        "\n",
        "dfx.to_csv(\"./RNN Results.csv\", sep=',', encoding='UTF-8')\n",
        "\n",
        "dfx.head(6)"
      ],
      "metadata": {
        "id": "b6W2OOeupUX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "EwZa81ThPbt3",
        "q6FO9rxjxHe_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}